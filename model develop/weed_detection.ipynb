{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0411bb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolov8s.pt to 'yolov8s.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 21.5MB 6.4MB/s 3.4s3.3s<0.1ssss\n",
      "Ultralytics 8.4.2 ğŸš€ Python-3.13.11 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5806MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/mnt/volume1/weedDataset/WeedCrop.v1i.yolov5pytorch/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=0.0, name=crop_weed_yolov8, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/mnt/volume1/Final year project/venv/runs/detect/crop_weed_yolov8, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/home/alaine/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 3.4MB/s 0.2s 0.2s<0.0s7s\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2116822  ultralytics.nn.modules.head.Detect           [2, 16, None, [128, 256, 512]]\n",
      "Model summary: 130 layers, 11,136,374 parameters, 11,136,358 gradients, 28.6 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 13.3MB/s 0.4s.3s<0.2s2s2s\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.1Â±0.0 ms, read: 114.0Â±41.0 MB/s, size: 95.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/volume1/weedDataset/WeedCrop.v1i.yolov5pytorch/train/labels... 2469 images, 101 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2469/2469 991.2it/s 2.5s.1ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /mnt/volume1/weedDataset/WeedCrop.v1i.yolov5pytorch/train/labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.4 ms, read: 127.6Â±64.2 MB/s, size: 133.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/volume1/weedDataset/WeedCrop.v1i.yolov5pytorch/valid/labels... 235 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 235/235 811.7it/s 0.3s0.2s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /mnt/volume1/weedDataset/WeedCrop.v1i.yolov5pytorch/valid/labels.cache\n",
      "Plotting labels to /mnt/volume1/Final year project/venv/runs/detect/crop_weed_yolov8/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m MuSGD(lr=0.001667, momentum=0.9) with parameter groups 0 weight(decay=0.0), 0 weight(decay=0.0005), 0 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/mnt/volume1/Final year project/venv/runs/detect/crop_weed_yolov8\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      1/100      3.54G       2.99      3.798      1.435         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 2.9it/s 53.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.4it/s 2.3s0.2ss\n",
      "                   all        235       1605      0.245       0.35      0.252       0.11\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      2/100      3.55G      2.569      2.069      1.203         37        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.3it/s 46.9s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.2it/s 1.3s0.2s\n",
      "                   all        235       1605      0.448      0.496      0.439      0.226\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      3/100      3.57G      2.443      1.913      1.146         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 44.9s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.2it/s 1.3s0.2s\n",
      "                   all        235       1605      0.447      0.563      0.453      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      4/100      3.56G      2.345      1.768      1.109         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.0s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.2it/s 1.3s0.2s\n",
      "                   all        235       1605      0.472      0.575      0.521      0.247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      5/100      3.58G      2.254      1.634      1.086         68        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.5it/s 44.9s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.3it/s 1.3s0.2s\n",
      "                   all        235       1605      0.532       0.59      0.547      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      6/100      3.56G      2.167      1.541      1.056         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 44.9s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.3it/s 1.3s0.2s\n",
      "                   all        235       1605      0.526      0.464      0.522       0.28\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      7/100       3.6G       2.12      1.463      1.047         81        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.1s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.3it/s 1.3s0.2s\n",
      "                   all        235       1605      0.638      0.592        0.6      0.326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      8/100      3.54G      2.038      1.373      1.029         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.2s0.3ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.3it/s 1.3s0.2s\n",
      "                   all        235       1605      0.534       0.58       0.58      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      9/100      3.59G      1.981      1.323      1.018         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.3it/s 1.3s0.2s\n",
      "                   all        235       1605      0.602       0.56      0.571      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     10/100      3.55G      1.938      1.264      1.004         75        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.4it/s 1.3s0.2s\n",
      "                   all        235       1605      0.684       0.56      0.612      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     11/100      3.57G      1.943      1.263      1.006         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.2s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.1it/s 1.3s0.2s\n",
      "                   all        235       1605      0.628      0.565      0.586      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     12/100       3.6G      1.879      1.217     0.9906         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.3s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.1it/s 1.3s0.2s\n",
      "                   all        235       1605       0.72      0.699      0.699      0.378\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     13/100      3.59G      1.855      1.181     0.9825         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.4s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.2it/s 1.3s0.2s\n",
      "                   all        235       1605      0.678      0.626       0.61      0.316\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     14/100      3.54G      1.852      1.174     0.9911         69        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.4s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.3it/s 1.3s0.2s\n",
      "                   all        235       1605      0.485      0.611      0.546       0.28\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     15/100      3.58G      1.816      1.138       0.97         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.5s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.3it/s 1.3s0.2s\n",
      "                   all        235       1605      0.684      0.541      0.608      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     16/100      3.53G      1.783      1.118     0.9627         63        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.5s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.3it/s 1.3s0.2s\n",
      "                   all        235       1605      0.676      0.685      0.682       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     17/100      3.55G      1.784      1.105     0.9649         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.5s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.1it/s 1.3s0.2s\n",
      "                   all        235       1605      0.681      0.689      0.695       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     18/100      3.62G      1.745      1.084     0.9556         37        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.6s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.4it/s 1.3s0.2s\n",
      "                   all        235       1605      0.723      0.678      0.713      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     19/100      3.58G      1.744      1.072     0.9652         51        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.6s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.2it/s 1.3s0.2s\n",
      "                   all        235       1605      0.653      0.657      0.644      0.338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     20/100      3.54G      1.722      1.053     0.9542         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.5s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.3it/s 1.3s0.2s\n",
      "                   all        235       1605      0.643      0.653      0.655       0.34\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     21/100      3.61G      1.719      1.051     0.9553         53        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.5s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.3it/s 1.3s0.2s\n",
      "                   all        235       1605      0.631      0.612      0.618      0.321\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     22/100      3.59G       1.69      1.028     0.9485         54        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.5s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.2it/s 1.3s0.2s\n",
      "                   all        235       1605       0.66      0.616      0.658      0.346\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     23/100      3.58G      1.663      1.017     0.9462         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.4it/s 45.4s0.6ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 6.3it/s 1.3s0.2s\n",
      "                   all        235       1605      0.635      0.639      0.624       0.32\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     24/100      3.61G      1.669      1.017     0.9439         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 3.8it/s 40.9s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.633      0.656      0.633      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     25/100      3.53G      1.645      0.997     0.9351         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.6it/s 34.0s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.623      0.595       0.58      0.299\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     26/100      3.51G      1.629     0.9786     0.9342         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.602      0.688       0.65       0.35\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     27/100      3.57G      1.619     0.9705     0.9365         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.8it/s 1.0s0.2s\n",
      "                   all        235       1605      0.681      0.731      0.687      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     28/100      3.62G      1.614     0.9628     0.9347         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.4s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.651      0.632      0.666      0.357\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     29/100      3.59G      1.598     0.9573     0.9285         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.6it/s 34.0s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.664      0.635       0.63      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     30/100      3.59G      1.576     0.9567     0.9283         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.716      0.663      0.637       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     31/100      3.57G      1.571     0.9404     0.9211         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.679       0.62      0.619      0.337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     32/100      3.55G      1.547     0.9256     0.9179         74        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.679      0.615      0.667      0.344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     33/100      3.58G      1.549     0.9095      0.914         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605      0.711      0.616      0.659      0.365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     34/100       3.6G      1.529     0.9112     0.9087         79        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.3s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.632      0.648      0.611      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     35/100      3.53G       1.54     0.9118     0.9174         48        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.7it/s 1.0s0.2s\n",
      "                   all        235       1605      0.714      0.631      0.665      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     36/100      3.65G      1.527     0.8902     0.9156         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.5s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.6it/s 1.0s0.2s\n",
      "                   all        235       1605      0.662      0.706      0.693      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     37/100       3.6G      1.497     0.8789     0.9074         60        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.3s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.6it/s 1.1s0.2s\n",
      "                   all        235       1605      0.732      0.657      0.686      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     38/100      3.54G      1.499      0.883      0.908         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.4s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.9it/s 1.0s0.1s\n",
      "                   all        235       1605      0.647       0.67      0.651      0.359\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     39/100      3.54G      1.484     0.8668      0.904         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.3s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.704      0.655      0.658      0.356\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     40/100      3.61G      1.489     0.8591     0.9068         55        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.4s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.678      0.638      0.615      0.327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     41/100      3.56G      1.463     0.8527     0.9035         65        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.3s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.9it/s 1.0s0.2s\n",
      "                   all        235       1605      0.711      0.681      0.685      0.364\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     42/100      3.54G      1.469     0.8517     0.9056         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.4s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.672      0.669      0.663      0.347\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     43/100      3.53G      1.445     0.8361     0.8964         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.9it/s 1.0s0.1s\n",
      "                   all        235       1605      0.729      0.621       0.67      0.368\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     44/100      3.59G      1.461     0.8419     0.9064         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.3s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.9it/s 1.0s0.1s\n",
      "                   all        235       1605      0.704      0.653      0.693      0.396\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     45/100       3.6G      1.448     0.8355     0.9005         76        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.9it/s 1.0s0.1s\n",
      "                   all        235       1605      0.662      0.728      0.705       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     46/100      3.54G      1.416     0.8124     0.8868         62        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.4s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.9it/s 1.0s0.1s\n",
      "                   all        235       1605      0.698      0.691       0.69      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     47/100       3.6G       1.42     0.8154     0.8931         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.4s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.0it/s 1.0s0.1s\n",
      "                   all        235       1605      0.657      0.593      0.627      0.338\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     48/100      3.63G      1.411     0.8076     0.8923         19        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.3s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.623      0.727      0.694      0.393\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     49/100      3.58G      1.402     0.8075     0.8928         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.598      0.702      0.655       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     50/100      3.59G      1.415     0.8143     0.8919         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.4s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.9it/s 1.0s0.2s\n",
      "                   all        235       1605      0.685      0.662      0.698      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     51/100      3.57G      1.388     0.7986     0.8905         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.7s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.5it/s 1.1s0.2s\n",
      "                   all        235       1605      0.711      0.655      0.681       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     52/100      3.61G      1.372     0.7815     0.8804         59        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.5s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.654      0.729      0.699      0.405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     53/100      3.63G      1.378     0.7869     0.8859         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.5s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.705      0.646      0.683      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     54/100      3.54G      1.354      0.768       0.88         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.3s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.673      0.684      0.646      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     55/100      3.56G      1.345     0.7666     0.8817         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.649      0.662      0.635      0.336\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     56/100      3.64G      1.354     0.7669     0.8786         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.4s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.714      0.691      0.685      0.383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     57/100      3.57G       1.34     0.7651     0.8792         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605      0.626      0.725      0.683      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     58/100      3.55G       1.34     0.7638     0.8811         55        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.0it/s 1.0s0.1s\n",
      "                   all        235       1605      0.626      0.695      0.668      0.374\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     59/100      3.62G      1.338     0.7603     0.8801         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605      0.697       0.64      0.685      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     60/100      3.56G      1.313     0.7453     0.8757         22        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.649      0.645      0.639      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     61/100      3.54G      1.325     0.7442     0.8742         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605      0.678      0.618      0.675       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     62/100      3.52G      1.311     0.7442      0.871         28        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.0it/s 1.0s0.1s\n",
      "                   all        235       1605      0.683      0.672      0.672      0.378\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     63/100      3.59G      1.318     0.7338     0.8771         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.699      0.671       0.67      0.365\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     64/100      3.63G      1.295     0.7258     0.8702         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.677      0.692      0.682      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     65/100      3.59G       1.28     0.7198     0.8702         53        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.665      0.624      0.639      0.355\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     66/100      3.63G        1.3     0.7209     0.8752         53        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.667      0.698      0.686      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     67/100      3.58G       1.28     0.7103     0.8705         69        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.646      0.683      0.672      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     68/100      3.64G      1.275      0.715     0.8673         60        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.668       0.66      0.667      0.369\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     69/100      3.59G      1.268     0.7073     0.8678         27        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.747      0.627      0.686      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     70/100      3.58G       1.25     0.6973     0.8674         47        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605       0.74       0.67      0.702      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     71/100      3.63G      1.236      0.689     0.8629         40        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.0it/s 1.0s0.2s\n",
      "                   all        235       1605      0.629      0.706      0.678      0.378\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     72/100      3.65G      1.247     0.6953     0.8688         48        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605      0.639      0.644      0.655      0.372\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     73/100      3.54G      1.251     0.6928     0.8612         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.711      0.667      0.686      0.383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     74/100      3.55G      1.235     0.6851     0.8597         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605      0.668      0.659       0.67       0.38\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     75/100      3.54G      1.225     0.6788     0.8618         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605      0.644      0.668       0.67      0.382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     76/100      3.57G      1.216     0.6775     0.8613         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.0it/s 1.0s0.1s\n",
      "                   all        235       1605       0.69      0.625      0.665      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     77/100      3.54G      1.206     0.6666     0.8597         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605        0.7       0.63      0.659      0.373\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     78/100       3.6G       1.22     0.6731     0.8561         44        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.677      0.641      0.665      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     79/100      3.56G      1.224     0.6757     0.8563         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.669      0.667      0.665      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     80/100      3.71G      1.204     0.6552     0.8567         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.657      0.671      0.691      0.404\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     81/100      3.54G      1.197     0.6599     0.8565         50        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605       0.67      0.626      0.666      0.379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     82/100      3.59G      1.207     0.6627     0.8587         68        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.623      0.692      0.674      0.389\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     83/100      3.52G      1.165     0.6435     0.8518         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.0it/s 1.0s0.1s\n",
      "                   all        235       1605       0.72      0.636      0.695        0.4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     84/100      3.61G      1.193     0.6591     0.8531         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.628      0.709       0.68      0.385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     85/100      3.56G      1.171     0.6462     0.8545         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.714      0.645      0.679      0.388\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     86/100      3.62G      1.166     0.6439     0.8543         26        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605      0.694      0.688      0.684      0.392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     87/100      3.53G      1.164     0.6379     0.8498         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.636      0.731      0.689      0.402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     88/100      3.61G       1.17     0.6432     0.8495         60        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.663      0.706      0.687      0.395\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     89/100      3.58G      1.149     0.6291      0.851         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.1s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605      0.677      0.673       0.68      0.375\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     90/100      3.54G      1.166     0.6398     0.8539         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.2s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605       0.68      0.686      0.697      0.402\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     91/100      3.54G      1.119     0.6085     0.8587          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.5it/s 34.6s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.1it/s 1.0s0.1s\n",
      "                   all        235       1605      0.728       0.67      0.706      0.398\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     92/100      3.54G      1.081     0.5919     0.8489         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.6it/s 34.0s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605       0.68      0.663       0.67      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     93/100       3.5G      1.067     0.5822     0.8505         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.6it/s 33.8s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.2it/s 1.0s0.1s\n",
      "                   all        235       1605      0.685      0.668      0.676      0.384\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     94/100       3.5G      1.055      0.575      0.847         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.6it/s 33.9s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.9it/s 1.0s0.1s\n",
      "                   all        235       1605      0.668      0.698       0.69      0.403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     95/100      3.46G      1.041     0.5679     0.8481         16        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.6it/s 33.9s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.0it/s 1.0s0.1s\n",
      "                   all        235       1605      0.665      0.686      0.677      0.387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     96/100      3.52G      1.035     0.5616     0.8402         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.6it/s 33.9s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.9it/s 1.0s0.1s\n",
      "                   all        235       1605      0.684      0.695      0.688      0.394\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     97/100      3.48G       1.03     0.5603     0.8444         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.6it/s 33.8s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.9it/s 1.0s0.1s\n",
      "                   all        235       1605       0.67       0.71      0.692      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     98/100      3.51G      1.031     0.5582      0.844         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.6it/s 34.0s0.4ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.0it/s 1.0s0.2s\n",
      "                   all        235       1605      0.681      0.687      0.687      0.389\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K     99/100      3.53G       1.02     0.5519     0.8422         17        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.6it/s 33.9s0.5ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 8.0it/s 1.0s0.1s\n",
      "                   all        235       1605      0.689      0.704      0.692      0.397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K    100/100      3.48G      1.026     0.5575     0.8394         29        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 155/155 4.6it/s 34.0s0.2ss\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 7.9it/s 1.0s0.1s\n",
      "                   all        235       1605      0.656       0.72      0.689      0.397\n",
      "\n",
      "100 epochs completed in 1.077 hours.\n",
      "Optimizer stripped from /mnt/volume1/Final year project/venv/runs/detect/crop_weed_yolov8/weights/last.pt, 22.5MB\n",
      "Optimizer stripped from /mnt/volume1/Final year project/venv/runs/detect/crop_weed_yolov8/weights/best.pt, 22.5MB\n",
      "\n",
      "Validating /mnt/volume1/Final year project/venv/runs/detect/crop_weed_yolov8/weights/best.pt...\n",
      "Ultralytics 8.4.2 ğŸš€ Python-3.13.11 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5806MiB)\n",
      "Model summary (fused): 73 layers, 11,126,358 parameters, 0 gradients, 28.4 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 4.6it/s 1.7s0.2s\n",
      "                   all        235       1605      0.654      0.729      0.699      0.406\n",
      "                  crop         17         47      0.643      0.689      0.671      0.451\n",
      "                  weed        228       1558      0.665      0.769      0.727      0.361\n",
      "Speed: 0.2ms preprocess, 2.2ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1m/mnt/volume1/Final year project/venv/runs/detect/crop_weed_yolov8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "def main():\n",
    "    # Load YOLOv8 model (latest CNN backbone)\n",
    "    model = YOLO(\"yolov8s.pt\")  # use yolov8n.pt for low-end GPU\n",
    "\n",
    "    # Train model\n",
    "    model.train(\n",
    "        data=\"..\\\\dataset\\\\data.yaml\",\n",
    "        epochs=100,\n",
    "        imgsz=640,\n",
    "        batch=16,\n",
    "        device=0,          # change to 'cpu' if no GPU\n",
    "        workers=8,\n",
    "        name=\"crop_weed_yolov8\"\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82604484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\Weed-detection-system\\model develop\\..\\dataset\\train\\images\\IMG_6202_JPG.rf.953875d61158a3eacb63ecb9dd563990.jpg: 384x640 5 weeds, 348.0ms\n",
      "Speed: 13.0ms preprocess, 348.0ms inference, 25.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "âœ… Output saved at: output\\result.jpg\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to trained model\n",
    "MODEL_PATH = \"best.pt\"\n",
    "\n",
    "# Path to your image\n",
    "IMAGE_PATH = \"..\\\\dataset\\\\train\\\\images\\\\IMG_6202_JPG.rf.953875d61158a3eacb63ecb9dd563990.jpg\"\n",
    "\n",
    "# Output folder\n",
    "OUTPUT_DIR = \"output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def main():\n",
    "    # Load model\n",
    "    model = YOLO(MODEL_PATH)\n",
    "\n",
    "    # Run inference\n",
    "    results = model(IMAGE_PATH, conf=0.3)\n",
    "\n",
    "    # Draw results\n",
    "    for r in results:\n",
    "        img = r.plot()  # draws boxes + labels\n",
    "\n",
    "        output_path = os.path.join(OUTPUT_DIR, \"result.jpg\")\n",
    "        cv2.imwrite(output_path, img)\n",
    "\n",
    "        print(f\"âœ… Output saved at: {output_path}\")\n",
    "\n",
    "        # Optional: show image\n",
    "        cv2.imshow(\"Weed Detection\", img)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b2a772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video... Press 'q' to stop early.\n",
      "\n",
      "0: 384x640 4 weeds, 289.6ms\n",
      "Speed: 12.8ms preprocess, 289.6ms inference, 19.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 229.1ms\n",
      "Speed: 5.0ms preprocess, 229.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 219.2ms\n",
      "Speed: 4.0ms preprocess, 219.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 227.1ms\n",
      "Speed: 8.0ms preprocess, 227.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 226.1ms\n",
      "Speed: 5.0ms preprocess, 226.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 229.1ms\n",
      "Speed: 5.0ms preprocess, 229.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 227.1ms\n",
      "Speed: 6.0ms preprocess, 227.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 219.3ms\n",
      "Speed: 5.0ms preprocess, 219.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 227.1ms\n",
      "Speed: 6.0ms preprocess, 227.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 256.1ms\n",
      "Speed: 4.0ms preprocess, 256.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 220.1ms\n",
      "Speed: 6.0ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 220.1ms\n",
      "Speed: 4.0ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 220.8ms\n",
      "Speed: 3.0ms preprocess, 220.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 223.6ms\n",
      "Speed: 4.0ms preprocess, 223.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 224.2ms\n",
      "Speed: 5.0ms preprocess, 224.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 222.1ms\n",
      "Speed: 5.0ms preprocess, 222.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 224.1ms\n",
      "Speed: 5.0ms preprocess, 224.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 220.9ms\n",
      "Speed: 5.0ms preprocess, 220.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 218.6ms\n",
      "Speed: 4.0ms preprocess, 218.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 226.7ms\n",
      "Speed: 4.0ms preprocess, 226.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 230.6ms\n",
      "Speed: 5.0ms preprocess, 230.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 228.0ms\n",
      "Speed: 4.0ms preprocess, 228.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 224.6ms\n",
      "Speed: 4.0ms preprocess, 224.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 226.2ms\n",
      "Speed: 4.0ms preprocess, 226.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 228.2ms\n",
      "Speed: 4.0ms preprocess, 228.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 231.9ms\n",
      "Speed: 5.0ms preprocess, 231.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 221.1ms\n",
      "Speed: 4.0ms preprocess, 221.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 230.1ms\n",
      "Speed: 4.0ms preprocess, 230.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 221.1ms\n",
      "Speed: 4.0ms preprocess, 221.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 229.1ms\n",
      "Speed: 3.0ms preprocess, 229.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 236.2ms\n",
      "Speed: 5.0ms preprocess, 236.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 226.1ms\n",
      "Speed: 4.0ms preprocess, 226.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 225.1ms\n",
      "Speed: 4.0ms preprocess, 225.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 244.6ms\n",
      "Speed: 4.0ms preprocess, 244.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 228.1ms\n",
      "Speed: 4.0ms preprocess, 228.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 224.1ms\n",
      "Speed: 5.5ms preprocess, 224.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 228.7ms\n",
      "Speed: 5.0ms preprocess, 228.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 221.7ms\n",
      "Speed: 4.0ms preprocess, 221.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 223.7ms\n",
      "Speed: 4.0ms preprocess, 223.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 224.2ms\n",
      "Speed: 5.0ms preprocess, 224.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 223.1ms\n",
      "Speed: 5.0ms preprocess, 223.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 220.1ms\n",
      "Speed: 4.0ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 225.1ms\n",
      "Speed: 5.0ms preprocess, 225.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 216.1ms\n",
      "Speed: 4.0ms preprocess, 216.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 224.6ms\n",
      "Speed: 5.0ms preprocess, 224.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 216.1ms\n",
      "Speed: 5.0ms preprocess, 216.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 223.2ms\n",
      "Speed: 5.0ms preprocess, 223.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 226.1ms\n",
      "Speed: 5.0ms preprocess, 226.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 220.1ms\n",
      "Speed: 4.0ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 228.1ms\n",
      "Speed: 5.0ms preprocess, 228.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 226.1ms\n",
      "Speed: 5.5ms preprocess, 226.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 225.6ms\n",
      "Speed: 4.0ms preprocess, 225.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 229.7ms\n",
      "Speed: 4.0ms preprocess, 229.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 223.1ms\n",
      "Speed: 5.0ms preprocess, 223.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 232.2ms\n",
      "Speed: 4.0ms preprocess, 232.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 246.7ms\n",
      "Speed: 4.0ms preprocess, 246.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 235.2ms\n",
      "Speed: 5.0ms preprocess, 235.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 227.5ms\n",
      "Speed: 4.0ms preprocess, 227.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 266.7ms\n",
      "Speed: 8.0ms preprocess, 266.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 239.2ms\n",
      "Speed: 7.5ms preprocess, 239.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 228.1ms\n",
      "Speed: 7.0ms preprocess, 228.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 236.1ms\n",
      "Speed: 5.0ms preprocess, 236.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 269.8ms\n",
      "Speed: 4.0ms preprocess, 269.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 283.6ms\n",
      "Speed: 7.0ms preprocess, 283.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 218.2ms\n",
      "Speed: 4.0ms preprocess, 218.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 223.1ms\n",
      "Speed: 4.0ms preprocess, 223.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 231.2ms\n",
      "Speed: 4.0ms preprocess, 231.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 223.1ms\n",
      "Speed: 4.0ms preprocess, 223.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 238.1ms\n",
      "Speed: 4.0ms preprocess, 238.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 221.1ms\n",
      "Speed: 4.0ms preprocess, 221.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 226.1ms\n",
      "Speed: 4.0ms preprocess, 226.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 219.1ms\n",
      "Speed: 4.5ms preprocess, 219.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 220.1ms\n",
      "Speed: 5.0ms preprocess, 220.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 224.1ms\n",
      "Speed: 3.5ms preprocess, 224.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 225.7ms\n",
      "Speed: 4.0ms preprocess, 225.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 225.1ms\n",
      "Speed: 4.0ms preprocess, 225.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 222.1ms\n",
      "Speed: 4.0ms preprocess, 222.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 227.1ms\n",
      "Speed: 4.0ms preprocess, 227.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 214.1ms\n",
      "Speed: 4.0ms preprocess, 214.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 239.7ms\n",
      "Speed: 7.0ms preprocess, 239.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 232.1ms\n",
      "Speed: 3.5ms preprocess, 232.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 269.1ms\n",
      "Speed: 4.5ms preprocess, 269.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 262.6ms\n",
      "Speed: 5.0ms preprocess, 262.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 229.7ms\n",
      "Speed: 5.0ms preprocess, 229.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 232.7ms\n",
      "Speed: 5.0ms preprocess, 232.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 226.6ms\n",
      "Speed: 4.0ms preprocess, 226.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 228.3ms\n",
      "Speed: 4.0ms preprocess, 228.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 223.1ms\n",
      "Speed: 4.0ms preprocess, 223.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 222.1ms\n",
      "Speed: 4.0ms preprocess, 222.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 233.2ms\n",
      "Speed: 5.0ms preprocess, 233.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 222.1ms\n",
      "Speed: 5.0ms preprocess, 222.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 231.1ms\n",
      "Speed: 5.0ms preprocess, 231.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 217.2ms\n",
      "Speed: 4.0ms preprocess, 217.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 221.7ms\n",
      "Speed: 4.0ms preprocess, 221.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 229.2ms\n",
      "Speed: 4.0ms preprocess, 229.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 240.9ms\n",
      "Speed: 7.0ms preprocess, 240.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 227.7ms\n",
      "Speed: 3.0ms preprocess, 227.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 232.6ms\n",
      "Speed: 4.0ms preprocess, 232.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 239.7ms\n",
      "Speed: 4.0ms preprocess, 239.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 231.2ms\n",
      "Speed: 4.0ms preprocess, 231.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 247.1ms\n",
      "Speed: 4.0ms preprocess, 247.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 218.1ms\n",
      "Speed: 5.0ms preprocess, 218.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 227.1ms\n",
      "Speed: 4.0ms preprocess, 227.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 222.1ms\n",
      "Speed: 4.5ms preprocess, 222.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 210.2ms\n",
      "Speed: 4.0ms preprocess, 210.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 213.6ms\n",
      "Speed: 4.0ms preprocess, 213.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 212.1ms\n",
      "Speed: 4.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 221.1ms\n",
      "Speed: 4.0ms preprocess, 221.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 216.1ms\n",
      "Speed: 4.0ms preprocess, 216.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 222.6ms\n",
      "Speed: 4.0ms preprocess, 222.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 221.1ms\n",
      "Speed: 5.0ms preprocess, 221.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 212.1ms\n",
      "Speed: 4.0ms preprocess, 212.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 212.1ms\n",
      "Speed: 4.5ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 weeds, 218.1ms\n",
      "Speed: 4.0ms preprocess, 218.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 221.1ms\n",
      "Speed: 4.0ms preprocess, 221.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 265.6ms\n",
      "Speed: 5.0ms preprocess, 265.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 207.1ms\n",
      "Speed: 5.0ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 208.2ms\n",
      "Speed: 5.0ms preprocess, 208.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 212.1ms\n",
      "Speed: 5.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 210.1ms\n",
      "Speed: 3.5ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 213.1ms\n",
      "Speed: 3.0ms preprocess, 213.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 188.1ms\n",
      "Speed: 3.0ms preprocess, 188.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 210.1ms\n",
      "Speed: 4.5ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 209.2ms\n",
      "Speed: 4.0ms preprocess, 209.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 207.1ms\n",
      "Speed: 4.0ms preprocess, 207.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 205.1ms\n",
      "Speed: 5.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 193.1ms\n",
      "Speed: 3.0ms preprocess, 193.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 219.2ms\n",
      "Speed: 5.0ms preprocess, 219.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 206.3ms\n",
      "Speed: 4.0ms preprocess, 206.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 212.1ms\n",
      "Speed: 4.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 236.7ms\n",
      "Speed: 4.0ms preprocess, 236.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 225.1ms\n",
      "Speed: 4.0ms preprocess, 225.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 209.6ms\n",
      "Speed: 4.0ms preprocess, 209.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 240.6ms\n",
      "Speed: 4.0ms preprocess, 240.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 208.1ms\n",
      "Speed: 3.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 205.2ms\n",
      "Speed: 4.0ms preprocess, 205.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 209.2ms\n",
      "Speed: 5.0ms preprocess, 209.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 209.6ms\n",
      "Speed: 3.0ms preprocess, 209.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 203.1ms\n",
      "Speed: 5.0ms preprocess, 203.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 206.1ms\n",
      "Speed: 4.0ms preprocess, 206.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 14 weeds, 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 207.1ms\n",
      "Speed: 5.0ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 215.1ms\n",
      "Speed: 3.5ms preprocess, 215.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 232.6ms\n",
      "Speed: 5.0ms preprocess, 232.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 230.1ms\n",
      "Speed: 4.0ms preprocess, 230.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 225.0ms\n",
      "Speed: 3.0ms preprocess, 225.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 208.1ms\n",
      "Speed: 3.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 217.6ms\n",
      "Speed: 4.0ms preprocess, 217.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 212.6ms\n",
      "Speed: 4.0ms preprocess, 212.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 236.6ms\n",
      "Speed: 4.0ms preprocess, 236.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 210.0ms\n",
      "Speed: 4.0ms preprocess, 210.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 260.6ms\n",
      "Speed: 3.0ms preprocess, 260.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 231.2ms\n",
      "Speed: 5.0ms preprocess, 231.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 227.1ms\n",
      "Speed: 3.0ms preprocess, 227.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 239.1ms\n",
      "Speed: 4.0ms preprocess, 239.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 215.2ms\n",
      "Speed: 4.0ms preprocess, 215.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 212.1ms\n",
      "Speed: 4.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 226.1ms\n",
      "Speed: 3.0ms preprocess, 226.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 weeds, 218.1ms\n",
      "Speed: 4.0ms preprocess, 218.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 223.7ms\n",
      "Speed: 4.0ms preprocess, 223.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 207.1ms\n",
      "Speed: 4.0ms preprocess, 207.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 223.1ms\n",
      "Speed: 4.0ms preprocess, 223.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 214.1ms\n",
      "Speed: 4.0ms preprocess, 214.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 213.1ms\n",
      "Speed: 4.0ms preprocess, 213.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 211.6ms\n",
      "Speed: 4.0ms preprocess, 211.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 216.1ms\n",
      "Speed: 4.0ms preprocess, 216.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 218.1ms\n",
      "Speed: 4.0ms preprocess, 218.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 223.0ms\n",
      "Speed: 5.1ms preprocess, 223.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 214.0ms\n",
      "Speed: 5.0ms preprocess, 214.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 225.7ms\n",
      "Speed: 4.0ms preprocess, 225.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 218.1ms\n",
      "Speed: 4.0ms preprocess, 218.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 223.1ms\n",
      "Speed: 4.0ms preprocess, 223.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 215.6ms\n",
      "Speed: 4.0ms preprocess, 215.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 218.2ms\n",
      "Speed: 4.0ms preprocess, 218.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 212.1ms\n",
      "Speed: 4.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 195.1ms\n",
      "Speed: 4.0ms preprocess, 195.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 212.0ms\n",
      "Speed: 4.0ms preprocess, 212.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 207.1ms\n",
      "Speed: 3.0ms preprocess, 207.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 214.6ms\n",
      "Speed: 4.0ms preprocess, 214.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 212.1ms\n",
      "Speed: 3.0ms preprocess, 212.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 204.7ms\n",
      "Speed: 5.0ms preprocess, 204.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 211.2ms\n",
      "Speed: 4.0ms preprocess, 211.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.2ms\n",
      "Speed: 4.0ms preprocess, 208.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 205.2ms\n",
      "Speed: 4.0ms preprocess, 205.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 215.1ms\n",
      "Speed: 4.0ms preprocess, 215.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 211.1ms\n",
      "Speed: 5.0ms preprocess, 211.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 219.1ms\n",
      "Speed: 5.0ms preprocess, 219.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.0ms\n",
      "Speed: 4.0ms preprocess, 208.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.2ms\n",
      "Speed: 4.0ms preprocess, 208.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 226.1ms\n",
      "Speed: 4.0ms preprocess, 226.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 213.1ms\n",
      "Speed: 4.0ms preprocess, 213.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 215.1ms\n",
      "Speed: 4.0ms preprocess, 215.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 213.2ms\n",
      "Speed: 4.0ms preprocess, 213.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 212.6ms\n",
      "Speed: 3.0ms preprocess, 212.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 206.1ms\n",
      "Speed: 4.0ms preprocess, 206.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 206.1ms\n",
      "Speed: 3.0ms preprocess, 206.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 207.7ms\n",
      "Speed: 4.0ms preprocess, 207.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 221.1ms\n",
      "Speed: 5.0ms preprocess, 221.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 213.1ms\n",
      "Speed: 3.0ms preprocess, 213.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 213.1ms\n",
      "Speed: 3.0ms preprocess, 213.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.6ms\n",
      "Speed: 5.0ms preprocess, 210.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 206.1ms\n",
      "Speed: 4.0ms preprocess, 206.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 204.0ms\n",
      "Speed: 4.0ms preprocess, 204.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 211.1ms\n",
      "Speed: 3.0ms preprocess, 211.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 211.3ms\n",
      "Speed: 3.0ms preprocess, 211.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 221.6ms\n",
      "Speed: 4.0ms preprocess, 221.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 212.1ms\n",
      "Speed: 5.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 223.7ms\n",
      "Speed: 4.0ms preprocess, 223.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 203.1ms\n",
      "Speed: 4.0ms preprocess, 203.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 207.1ms\n",
      "Speed: 3.0ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 202.1ms\n",
      "Speed: 4.0ms preprocess, 202.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 206.1ms\n",
      "Speed: 5.0ms preprocess, 206.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 203.1ms\n",
      "Speed: 4.0ms preprocess, 203.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 202.1ms\n",
      "Speed: 4.0ms preprocess, 202.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 208.8ms\n",
      "Speed: 5.0ms preprocess, 208.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 204.1ms\n",
      "Speed: 3.0ms preprocess, 204.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 204.1ms\n",
      "Speed: 4.0ms preprocess, 204.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 205.2ms\n",
      "Speed: 4.0ms preprocess, 205.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 202.9ms\n",
      "Speed: 5.0ms preprocess, 202.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 203.1ms\n",
      "Speed: 4.0ms preprocess, 203.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 204.1ms\n",
      "Speed: 5.0ms preprocess, 204.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 208.1ms\n",
      "Speed: 5.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 207.1ms\n",
      "Speed: 4.0ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 211.2ms\n",
      "Speed: 4.0ms preprocess, 211.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 206.1ms\n",
      "Speed: 4.0ms preprocess, 206.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 215.1ms\n",
      "Speed: 4.0ms preprocess, 215.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 210.7ms\n",
      "Speed: 4.0ms preprocess, 210.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 215.1ms\n",
      "Speed: 3.0ms preprocess, 215.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 215.1ms\n",
      "Speed: 4.0ms preprocess, 215.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 210.1ms\n",
      "Speed: 3.5ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 207.1ms\n",
      "Speed: 4.0ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 204.1ms\n",
      "Speed: 4.0ms preprocess, 204.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 202.1ms\n",
      "Speed: 3.0ms preprocess, 202.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 204.1ms\n",
      "Speed: 4.0ms preprocess, 204.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 214.6ms\n",
      "Speed: 4.0ms preprocess, 214.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 211.1ms\n",
      "Speed: 3.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 203.1ms\n",
      "Speed: 4.0ms preprocess, 203.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 207.1ms\n",
      "Speed: 3.5ms preprocess, 207.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 201.1ms\n",
      "Speed: 5.0ms preprocess, 201.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 204.8ms\n",
      "Speed: 4.0ms preprocess, 204.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 211.3ms\n",
      "Speed: 4.0ms preprocess, 211.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 207.0ms\n",
      "Speed: 3.0ms preprocess, 207.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 211.7ms\n",
      "Speed: 4.0ms preprocess, 211.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 214.6ms\n",
      "Speed: 4.0ms preprocess, 214.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 213.1ms\n",
      "Speed: 4.0ms preprocess, 213.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 206.1ms\n",
      "Speed: 5.0ms preprocess, 206.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 205.1ms\n",
      "Speed: 3.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 202.1ms\n",
      "Speed: 3.0ms preprocess, 202.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 204.1ms\n",
      "Speed: 4.0ms preprocess, 204.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 209.1ms\n",
      "Speed: 5.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 206.6ms\n",
      "Speed: 4.0ms preprocess, 206.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 weeds, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 215.8ms\n",
      "Speed: 4.0ms preprocess, 215.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 202.1ms\n",
      "Speed: 4.0ms preprocess, 202.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 204.7ms\n",
      "Speed: 4.0ms preprocess, 204.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 207.1ms\n",
      "Speed: 4.0ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 212.1ms\n",
      "Speed: 4.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 216.1ms\n",
      "Speed: 4.0ms preprocess, 216.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 209.0ms\n",
      "Speed: 4.0ms preprocess, 209.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 212.1ms\n",
      "Speed: 4.0ms preprocess, 212.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 212.7ms\n",
      "Speed: 5.0ms preprocess, 212.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 216.1ms\n",
      "Speed: 3.0ms preprocess, 216.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 217.6ms\n",
      "Speed: 3.0ms preprocess, 217.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 213.1ms\n",
      "Speed: 4.0ms preprocess, 213.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 215.1ms\n",
      "Speed: 3.0ms preprocess, 215.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.1ms\n",
      "Speed: 3.0ms preprocess, 208.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 203.1ms\n",
      "Speed: 4.0ms preprocess, 203.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 202.1ms\n",
      "Speed: 4.0ms preprocess, 202.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 204.1ms\n",
      "Speed: 4.0ms preprocess, 204.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 202.1ms\n",
      "Speed: 4.0ms preprocess, 202.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 216.1ms\n",
      "Speed: 4.0ms preprocess, 216.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 206.7ms\n",
      "Speed: 3.5ms preprocess, 206.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 207.2ms\n",
      "Speed: 4.0ms preprocess, 207.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.6ms\n",
      "Speed: 5.0ms preprocess, 210.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 202.1ms\n",
      "Speed: 3.0ms preprocess, 202.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 200.1ms\n",
      "Speed: 4.0ms preprocess, 200.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 203.3ms\n",
      "Speed: 3.0ms preprocess, 203.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 218.6ms\n",
      "Speed: 4.0ms preprocess, 218.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 211.1ms\n",
      "Speed: 5.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 216.8ms\n",
      "Speed: 5.0ms preprocess, 216.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 205.2ms\n",
      "Speed: 5.0ms preprocess, 205.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 214.3ms\n",
      "Speed: 5.2ms preprocess, 214.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 224.7ms\n",
      "Speed: 4.0ms preprocess, 224.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 232.1ms\n",
      "Speed: 4.0ms preprocess, 232.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 207.8ms\n",
      "Speed: 4.0ms preprocess, 207.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 225.1ms\n",
      "Speed: 4.0ms preprocess, 225.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 224.1ms\n",
      "Speed: 5.0ms preprocess, 224.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 214.6ms\n",
      "Speed: 4.0ms preprocess, 214.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 204.1ms\n",
      "Speed: 4.0ms preprocess, 204.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 211.6ms\n",
      "Speed: 4.0ms preprocess, 211.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 227.2ms\n",
      "Speed: 4.0ms preprocess, 227.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 200.1ms\n",
      "Speed: 4.0ms preprocess, 200.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 215.1ms\n",
      "Speed: 3.5ms preprocess, 215.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 221.1ms\n",
      "Speed: 4.0ms preprocess, 221.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 248.6ms\n",
      "Speed: 6.0ms preprocess, 248.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 226.7ms\n",
      "Speed: 4.5ms preprocess, 226.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 228.6ms\n",
      "Speed: 4.0ms preprocess, 228.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 215.1ms\n",
      "Speed: 4.0ms preprocess, 215.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 221.1ms\n",
      "Speed: 4.0ms preprocess, 221.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 weed, 222.1ms\n",
      "Speed: 4.0ms preprocess, 222.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 238.1ms\n",
      "Speed: 5.0ms preprocess, 238.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 212.1ms\n",
      "Speed: 4.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 211.6ms\n",
      "Speed: 4.0ms preprocess, 211.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 225.1ms\n",
      "Speed: 4.0ms preprocess, 225.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 212.1ms\n",
      "Speed: 4.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 207.2ms\n",
      "Speed: 4.0ms preprocess, 207.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 198.1ms\n",
      "Speed: 5.0ms preprocess, 198.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 224.1ms\n",
      "Speed: 4.0ms preprocess, 224.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 215.6ms\n",
      "Speed: 4.0ms preprocess, 215.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 214.2ms\n",
      "Speed: 4.0ms preprocess, 214.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 213.1ms\n",
      "Speed: 6.0ms preprocess, 213.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 206.1ms\n",
      "Speed: 5.0ms preprocess, 206.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 208.1ms\n",
      "Speed: 5.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 212.1ms\n",
      "Speed: 4.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 206.1ms\n",
      "Speed: 4.0ms preprocess, 206.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 212.1ms\n",
      "Speed: 5.0ms preprocess, 212.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 226.6ms\n",
      "Speed: 4.0ms preprocess, 226.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 213.1ms\n",
      "Speed: 4.0ms preprocess, 213.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 204.1ms\n",
      "Speed: 4.0ms preprocess, 204.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 207.2ms\n",
      "Speed: 4.0ms preprocess, 207.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 218.1ms\n",
      "Speed: 5.0ms preprocess, 218.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 214.7ms\n",
      "Speed: 4.0ms preprocess, 214.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 209.1ms\n",
      "Speed: 5.0ms preprocess, 209.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 212.1ms\n",
      "Speed: 5.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 206.1ms\n",
      "Speed: 4.5ms preprocess, 206.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 206.2ms\n",
      "Speed: 4.0ms preprocess, 206.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 215.7ms\n",
      "Speed: 4.0ms preprocess, 215.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 216.1ms\n",
      "Speed: 5.0ms preprocess, 216.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 212.6ms\n",
      "Speed: 3.0ms preprocess, 212.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 224.1ms\n",
      "Speed: 6.0ms preprocess, 224.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 220.9ms\n",
      "Speed: 4.0ms preprocess, 220.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 220.1ms\n",
      "Speed: 4.0ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 221.1ms\n",
      "Speed: 4.0ms preprocess, 221.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 226.6ms\n",
      "Speed: 5.0ms preprocess, 226.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 221.1ms\n",
      "Speed: 4.0ms preprocess, 221.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 253.1ms\n",
      "Speed: 5.0ms preprocess, 253.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 226.1ms\n",
      "Speed: 4.0ms preprocess, 226.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 229.1ms\n",
      "Speed: 4.0ms preprocess, 229.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 220.1ms\n",
      "Speed: 3.0ms preprocess, 220.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 214.1ms\n",
      "Speed: 3.5ms preprocess, 214.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 216.2ms\n",
      "Speed: 4.0ms preprocess, 216.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 217.1ms\n",
      "Speed: 6.0ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 214.7ms\n",
      "Speed: 4.0ms preprocess, 214.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 215.7ms\n",
      "Speed: 4.0ms preprocess, 215.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 216.1ms\n",
      "Speed: 4.0ms preprocess, 216.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 213.1ms\n",
      "Speed: 5.0ms preprocess, 213.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 208.1ms\n",
      "Speed: 5.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 221.1ms\n",
      "Speed: 3.5ms preprocess, 221.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 220.7ms\n",
      "Speed: 3.0ms preprocess, 220.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 203.1ms\n",
      "Speed: 4.0ms preprocess, 203.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 227.1ms\n",
      "Speed: 4.0ms preprocess, 227.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 215.1ms\n",
      "Speed: 4.0ms preprocess, 215.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 217.7ms\n",
      "Speed: 5.0ms preprocess, 217.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 211.1ms\n",
      "Speed: 4.0ms preprocess, 211.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 210.1ms\n",
      "Speed: 3.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 217.6ms\n",
      "Speed: 4.0ms preprocess, 217.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 238.7ms\n",
      "Speed: 5.0ms preprocess, 238.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 207.1ms\n",
      "Speed: 3.0ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 212.1ms\n",
      "Speed: 3.5ms preprocess, 212.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 203.1ms\n",
      "Speed: 4.0ms preprocess, 203.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 202.0ms\n",
      "Speed: 4.0ms preprocess, 202.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 209.1ms\n",
      "Speed: 4.5ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 211.1ms\n",
      "Speed: 5.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 215.1ms\n",
      "Speed: 4.0ms preprocess, 215.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 206.1ms\n",
      "Speed: 5.0ms preprocess, 206.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 207.1ms\n",
      "Speed: 4.0ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 217.0ms\n",
      "Speed: 5.0ms preprocess, 217.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 216.6ms\n",
      "Speed: 4.0ms preprocess, 216.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 219.6ms\n",
      "Speed: 4.0ms preprocess, 219.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 204.7ms\n",
      "Speed: 4.0ms preprocess, 204.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 222.1ms\n",
      "Speed: 4.0ms preprocess, 222.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 216.2ms\n",
      "Speed: 3.0ms preprocess, 216.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 205.1ms\n",
      "Speed: 5.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 210.6ms\n",
      "Speed: 4.0ms preprocess, 210.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 212.3ms\n",
      "Speed: 4.0ms preprocess, 212.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 216.1ms\n",
      "Speed: 4.0ms preprocess, 216.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 225.1ms\n",
      "Speed: 5.0ms preprocess, 225.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 208.1ms\n",
      "Speed: 3.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 207.1ms\n",
      "Speed: 4.0ms preprocess, 207.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 208.6ms\n",
      "Speed: 3.0ms preprocess, 208.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 208.1ms\n",
      "Speed: 4.0ms preprocess, 208.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 207.1ms\n",
      "Speed: 5.0ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 211.1ms\n",
      "Speed: 6.0ms preprocess, 211.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 207.1ms\n",
      "Speed: 4.5ms preprocess, 207.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 210.2ms\n",
      "Speed: 4.0ms preprocess, 210.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 209.1ms\n",
      "Speed: 3.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 210.2ms\n",
      "Speed: 4.0ms preprocess, 210.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 211.1ms\n",
      "Speed: 5.0ms preprocess, 211.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 210.1ms\n",
      "Speed: 5.0ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 209.1ms\n",
      "Speed: 3.0ms preprocess, 209.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 220.1ms\n",
      "Speed: 4.0ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 209.1ms\n",
      "Speed: 4.0ms preprocess, 209.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 207.1ms\n",
      "Speed: 4.5ms preprocess, 207.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 226.1ms\n",
      "Speed: 4.0ms preprocess, 226.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 207.1ms\n",
      "Speed: 5.0ms preprocess, 207.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 217.1ms\n",
      "Speed: 4.5ms preprocess, 217.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 221.6ms\n",
      "Speed: 4.0ms preprocess, 221.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 217.1ms\n",
      "Speed: 4.0ms preprocess, 217.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 199.1ms\n",
      "Speed: 4.0ms preprocess, 199.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 207.1ms\n",
      "Speed: 4.0ms preprocess, 207.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 206.1ms\n",
      "Speed: 4.0ms preprocess, 206.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 208.1ms\n",
      "Speed: 5.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 206.1ms\n",
      "Speed: 4.0ms preprocess, 206.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 211.7ms\n",
      "Speed: 4.0ms preprocess, 211.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 222.1ms\n",
      "Speed: 4.0ms preprocess, 222.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 206.1ms\n",
      "Speed: 4.0ms preprocess, 206.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 203.9ms\n",
      "Speed: 5.0ms preprocess, 203.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 209.1ms\n",
      "Speed: 5.0ms preprocess, 209.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 200.1ms\n",
      "Speed: 4.0ms preprocess, 200.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 213.1ms\n",
      "Speed: 5.0ms preprocess, 213.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 209.6ms\n",
      "Speed: 4.0ms preprocess, 209.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 212.1ms\n",
      "Speed: 4.0ms preprocess, 212.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 214.2ms\n",
      "Speed: 5.5ms preprocess, 214.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 208.1ms\n",
      "Speed: 5.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 236.1ms\n",
      "Speed: 4.0ms preprocess, 236.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 213.1ms\n",
      "Speed: 4.0ms preprocess, 213.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 230.1ms\n",
      "Speed: 4.0ms preprocess, 230.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 210.1ms\n",
      "Speed: 4.0ms preprocess, 210.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 212.1ms\n",
      "Speed: 5.0ms preprocess, 212.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 214.1ms\n",
      "Speed: 5.0ms preprocess, 214.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 203.1ms\n",
      "Speed: 4.0ms preprocess, 203.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 292.7ms\n",
      "Speed: 5.0ms preprocess, 292.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 237.1ms\n",
      "Speed: 4.0ms preprocess, 237.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 243.1ms\n",
      "Speed: 4.0ms preprocess, 243.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 230.1ms\n",
      "Speed: 7.0ms preprocess, 230.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 238.1ms\n",
      "Speed: 4.0ms preprocess, 238.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 230.1ms\n",
      "Speed: 4.0ms preprocess, 230.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 255.6ms\n",
      "Speed: 5.0ms preprocess, 255.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 236.6ms\n",
      "Speed: 5.0ms preprocess, 236.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 226.1ms\n",
      "Speed: 4.0ms preprocess, 226.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 228.1ms\n",
      "Speed: 4.0ms preprocess, 228.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 233.1ms\n",
      "Speed: 3.0ms preprocess, 233.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 219.1ms\n",
      "Speed: 4.0ms preprocess, 219.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 221.9ms\n",
      "Speed: 5.0ms preprocess, 221.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 225.1ms\n",
      "Speed: 4.0ms preprocess, 225.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 229.1ms\n",
      "Speed: 3.5ms preprocess, 229.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 221.7ms\n",
      "Speed: 5.0ms preprocess, 221.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 224.7ms\n",
      "Speed: 5.0ms preprocess, 224.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 230.1ms\n",
      "Speed: 5.0ms preprocess, 230.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 215.1ms\n",
      "Speed: 6.0ms preprocess, 215.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 227.1ms\n",
      "Speed: 4.0ms preprocess, 227.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 222.1ms\n",
      "Speed: 5.0ms preprocess, 222.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 236.1ms\n",
      "Speed: 5.0ms preprocess, 236.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 220.7ms\n",
      "Speed: 4.0ms preprocess, 220.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 217.7ms\n",
      "Speed: 4.0ms preprocess, 217.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 235.6ms\n",
      "Speed: 4.0ms preprocess, 235.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 222.1ms\n",
      "Speed: 4.0ms preprocess, 222.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 224.1ms\n",
      "Speed: 5.0ms preprocess, 224.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 218.1ms\n",
      "Speed: 5.0ms preprocess, 218.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 229.1ms\n",
      "Speed: 4.0ms preprocess, 229.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 283.6ms\n",
      "Speed: 4.0ms preprocess, 283.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 227.1ms\n",
      "Speed: 4.0ms preprocess, 227.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 225.1ms\n",
      "Speed: 5.0ms preprocess, 225.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 238.0ms\n",
      "Speed: 4.0ms preprocess, 238.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 234.1ms\n",
      "Speed: 5.0ms preprocess, 234.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 220.1ms\n",
      "Speed: 5.0ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 232.1ms\n",
      "Speed: 4.0ms preprocess, 232.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 weeds, 220.1ms\n",
      "Speed: 5.0ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 237.1ms\n",
      "Speed: 5.0ms preprocess, 237.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 219.2ms\n",
      "Speed: 4.0ms preprocess, 219.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 228.1ms\n",
      "Speed: 4.0ms preprocess, 228.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 223.9ms\n",
      "Speed: 5.0ms preprocess, 223.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 227.1ms\n",
      "Speed: 5.0ms preprocess, 227.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 240.1ms\n",
      "Speed: 4.0ms preprocess, 240.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 217.0ms\n",
      "Speed: 5.0ms preprocess, 217.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 206.1ms\n",
      "Speed: 5.0ms preprocess, 206.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 218.7ms\n",
      "Speed: 4.0ms preprocess, 218.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 210.1ms\n",
      "Speed: 4.5ms preprocess, 210.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 205.1ms\n",
      "Speed: 4.0ms preprocess, 205.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 207.7ms\n",
      "Speed: 4.0ms preprocess, 207.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 219.1ms\n",
      "Speed: 3.0ms preprocess, 219.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 237.1ms\n",
      "Speed: 4.0ms preprocess, 237.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 231.7ms\n",
      "Speed: 4.0ms preprocess, 231.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 263.2ms\n",
      "Speed: 4.0ms preprocess, 263.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 230.1ms\n",
      "Speed: 4.0ms preprocess, 230.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 218.8ms\n",
      "Speed: 4.0ms preprocess, 218.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 215.1ms\n",
      "Speed: 4.0ms preprocess, 215.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 228.1ms\n",
      "Speed: 4.0ms preprocess, 228.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 335.6ms\n",
      "Speed: 5.0ms preprocess, 335.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 233.1ms\n",
      "Speed: 5.0ms preprocess, 233.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 233.1ms\n",
      "Speed: 4.0ms preprocess, 233.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 227.6ms\n",
      "Speed: 5.0ms preprocess, 227.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 244.0ms\n",
      "Speed: 7.0ms preprocess, 244.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 250.0ms\n",
      "Speed: 4.0ms preprocess, 250.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 232.0ms\n",
      "Speed: 8.0ms preprocess, 232.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 223.0ms\n",
      "Speed: 7.0ms preprocess, 223.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 218.0ms\n",
      "Speed: 5.0ms preprocess, 218.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 243.0ms\n",
      "Speed: 5.0ms preprocess, 243.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 233.3ms\n",
      "Speed: 4.0ms preprocess, 233.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 294.0ms\n",
      "Speed: 6.0ms preprocess, 294.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 228.0ms\n",
      "Speed: 7.0ms preprocess, 228.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 217.0ms\n",
      "Speed: 5.0ms preprocess, 217.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 225.0ms\n",
      "Speed: 5.0ms preprocess, 225.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 226.0ms\n",
      "Speed: 4.0ms preprocess, 226.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 231.0ms\n",
      "Speed: 4.0ms preprocess, 231.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 219.0ms\n",
      "Speed: 5.0ms preprocess, 219.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 221.0ms\n",
      "Speed: 4.0ms preprocess, 221.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 215.0ms\n",
      "Speed: 5.0ms preprocess, 215.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 219.0ms\n",
      "Speed: 6.0ms preprocess, 219.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 221.0ms\n",
      "Speed: 5.0ms preprocess, 221.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 224.0ms\n",
      "Speed: 4.0ms preprocess, 224.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 222.0ms\n",
      "Speed: 4.0ms preprocess, 222.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 228.0ms\n",
      "Speed: 8.0ms preprocess, 228.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 216.0ms\n",
      "Speed: 5.0ms preprocess, 216.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 213.0ms\n",
      "Speed: 6.0ms preprocess, 213.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 217.0ms\n",
      "Speed: 5.0ms preprocess, 217.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 219.0ms\n",
      "Speed: 4.0ms preprocess, 219.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 227.0ms\n",
      "Speed: 6.0ms preprocess, 227.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 312.0ms\n",
      "Speed: 4.0ms preprocess, 312.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 232.0ms\n",
      "Speed: 6.0ms preprocess, 232.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 236.0ms\n",
      "Speed: 5.0ms preprocess, 236.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 224.0ms\n",
      "Speed: 4.0ms preprocess, 224.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 220.0ms\n",
      "Speed: 5.0ms preprocess, 220.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 216.0ms\n",
      "Speed: 5.0ms preprocess, 216.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 232.0ms\n",
      "Speed: 5.0ms preprocess, 232.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 227.2ms\n",
      "Speed: 4.0ms preprocess, 227.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 227.0ms\n",
      "Speed: 5.0ms preprocess, 227.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 216.0ms\n",
      "Speed: 4.0ms preprocess, 216.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 213.0ms\n",
      "Speed: 4.0ms preprocess, 213.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 weeds, 221.0ms\n",
      "Speed: 4.0ms preprocess, 221.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 211.0ms\n",
      "Speed: 4.0ms preprocess, 211.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 230.0ms\n",
      "Speed: 5.0ms preprocess, 230.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 222.0ms\n",
      "Speed: 6.0ms preprocess, 222.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 283.0ms\n",
      "Speed: 4.0ms preprocess, 283.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 211.0ms\n",
      "Speed: 5.0ms preprocess, 211.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 213.0ms\n",
      "Speed: 4.0ms preprocess, 213.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 231.0ms\n",
      "Speed: 6.0ms preprocess, 231.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 234.0ms\n",
      "Speed: 4.0ms preprocess, 234.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 227.0ms\n",
      "Speed: 5.0ms preprocess, 227.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 235.0ms\n",
      "Speed: 5.0ms preprocess, 235.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 235.0ms\n",
      "Speed: 5.0ms preprocess, 235.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 244.0ms\n",
      "Speed: 4.0ms preprocess, 244.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 352.0ms\n",
      "Speed: 5.0ms preprocess, 352.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 342.0ms\n",
      "Speed: 5.0ms preprocess, 342.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 257.0ms\n",
      "Speed: 6.0ms preprocess, 257.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 246.0ms\n",
      "Speed: 14.0ms preprocess, 246.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 283.0ms\n",
      "Speed: 4.0ms preprocess, 283.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 240.0ms\n",
      "Speed: 4.0ms preprocess, 240.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 222.1ms\n",
      "Speed: 5.0ms preprocess, 222.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 1084.0ms\n",
      "Speed: 6.0ms preprocess, 1084.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 831.3ms\n",
      "Speed: 22.0ms preprocess, 831.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 333.3ms\n",
      "Speed: 11.0ms preprocess, 333.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 294.0ms\n",
      "Speed: 5.0ms preprocess, 294.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 285.1ms\n",
      "Speed: 6.0ms preprocess, 285.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 254.7ms\n",
      "Speed: 7.0ms preprocess, 254.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 261.0ms\n",
      "Speed: 5.0ms preprocess, 261.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 239.2ms\n",
      "Speed: 6.0ms preprocess, 239.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 248.3ms\n",
      "Speed: 7.0ms preprocess, 248.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 236.7ms\n",
      "Speed: 4.0ms preprocess, 236.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 266.2ms\n",
      "Speed: 6.0ms preprocess, 266.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 244.1ms\n",
      "Speed: 6.0ms preprocess, 244.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 265.3ms\n",
      "Speed: 5.0ms preprocess, 265.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 234.6ms\n",
      "Speed: 8.0ms preprocess, 234.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 254.5ms\n",
      "Speed: 5.0ms preprocess, 254.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 235.5ms\n",
      "Speed: 5.0ms preprocess, 235.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 250.8ms\n",
      "Speed: 6.0ms preprocess, 250.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 252.0ms\n",
      "Speed: 5.0ms preprocess, 252.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 298.8ms\n",
      "Speed: 6.0ms preprocess, 298.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 260.8ms\n",
      "Speed: 6.0ms preprocess, 260.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 282.9ms\n",
      "Speed: 34.0ms preprocess, 282.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 253.7ms\n",
      "Speed: 6.0ms preprocess, 253.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 251.6ms\n",
      "Speed: 6.0ms preprocess, 251.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 261.7ms\n",
      "Speed: 7.0ms preprocess, 261.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 261.3ms\n",
      "Speed: 8.0ms preprocess, 261.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 255.6ms\n",
      "Speed: 6.0ms preprocess, 255.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 262.0ms\n",
      "Speed: 6.0ms preprocess, 262.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 266.5ms\n",
      "Speed: 17.0ms preprocess, 266.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 237.4ms\n",
      "Speed: 7.0ms preprocess, 237.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 241.8ms\n",
      "Speed: 6.0ms preprocess, 241.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 242.0ms\n",
      "Speed: 5.0ms preprocess, 242.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 255.8ms\n",
      "Speed: 4.0ms preprocess, 255.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 257.3ms\n",
      "Speed: 8.0ms preprocess, 257.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 251.3ms\n",
      "Speed: 7.0ms preprocess, 251.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 262.4ms\n",
      "Speed: 5.0ms preprocess, 262.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 255.7ms\n",
      "Speed: 6.0ms preprocess, 255.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 252.3ms\n",
      "Speed: 5.0ms preprocess, 252.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 274.8ms\n",
      "Speed: 8.0ms preprocess, 274.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 278.5ms\n",
      "Speed: 18.0ms preprocess, 278.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 300.6ms\n",
      "Speed: 6.0ms preprocess, 300.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 260.7ms\n",
      "Speed: 8.0ms preprocess, 260.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 249.8ms\n",
      "Speed: 8.0ms preprocess, 249.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 weeds, 277.5ms\n",
      "Speed: 5.0ms preprocess, 277.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 287.1ms\n",
      "Speed: 6.0ms preprocess, 287.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 259.8ms\n",
      "Speed: 8.0ms preprocess, 259.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 252.1ms\n",
      "Speed: 5.0ms preprocess, 252.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 254.8ms\n",
      "Speed: 7.0ms preprocess, 254.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 242.3ms\n",
      "Speed: 9.0ms preprocess, 242.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 240.2ms\n",
      "Speed: 5.0ms preprocess, 240.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 257.9ms\n",
      "Speed: 4.0ms preprocess, 257.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 244.3ms\n",
      "Speed: 5.0ms preprocess, 244.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 246.6ms\n",
      "Speed: 6.0ms preprocess, 246.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 247.2ms\n",
      "Speed: 5.0ms preprocess, 247.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 244.9ms\n",
      "Speed: 5.0ms preprocess, 244.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 233.7ms\n",
      "Speed: 5.0ms preprocess, 233.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 240.0ms\n",
      "Speed: 5.0ms preprocess, 240.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 256.9ms\n",
      "Speed: 17.0ms preprocess, 256.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 236.7ms\n",
      "Speed: 5.0ms preprocess, 236.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 234.7ms\n",
      "Speed: 5.0ms preprocess, 234.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 246.2ms\n",
      "Speed: 7.0ms preprocess, 246.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 244.6ms\n",
      "Speed: 5.0ms preprocess, 244.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 236.6ms\n",
      "Speed: 5.0ms preprocess, 236.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 243.3ms\n",
      "Speed: 6.0ms preprocess, 243.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 245.6ms\n",
      "Speed: 13.0ms preprocess, 245.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 239.1ms\n",
      "Speed: 5.0ms preprocess, 239.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 235.8ms\n",
      "Speed: 7.0ms preprocess, 235.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 236.8ms\n",
      "Speed: 6.0ms preprocess, 236.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 243.9ms\n",
      "Speed: 7.0ms preprocess, 243.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 240.2ms\n",
      "Speed: 5.0ms preprocess, 240.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 238.4ms\n",
      "Speed: 6.0ms preprocess, 238.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 251.0ms\n",
      "Speed: 4.0ms preprocess, 251.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 232.5ms\n",
      "Speed: 8.0ms preprocess, 232.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 238.6ms\n",
      "Speed: 5.0ms preprocess, 238.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 309.5ms\n",
      "Speed: 5.0ms preprocess, 309.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 231.8ms\n",
      "Speed: 6.0ms preprocess, 231.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 234.9ms\n",
      "Speed: 5.0ms preprocess, 234.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 239.2ms\n",
      "Speed: 6.0ms preprocess, 239.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 245.3ms\n",
      "Speed: 5.0ms preprocess, 245.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 241.6ms\n",
      "Speed: 6.0ms preprocess, 241.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 238.8ms\n",
      "Speed: 5.0ms preprocess, 238.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 236.8ms\n",
      "Speed: 5.0ms preprocess, 236.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 247.6ms\n",
      "Speed: 6.0ms preprocess, 247.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 253.6ms\n",
      "Speed: 6.0ms preprocess, 253.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 286.7ms\n",
      "Speed: 9.0ms preprocess, 286.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 259.4ms\n",
      "Speed: 4.0ms preprocess, 259.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 305.6ms\n",
      "Speed: 7.0ms preprocess, 305.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 297.8ms\n",
      "Speed: 5.0ms preprocess, 297.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 288.9ms\n",
      "Speed: 5.0ms preprocess, 288.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 277.9ms\n",
      "Speed: 6.0ms preprocess, 277.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 258.0ms\n",
      "Speed: 9.0ms preprocess, 258.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 253.2ms\n",
      "Speed: 8.2ms preprocess, 253.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 262.9ms\n",
      "Speed: 20.0ms preprocess, 262.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 245.4ms\n",
      "Speed: 5.0ms preprocess, 245.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 246.4ms\n",
      "Speed: 5.0ms preprocess, 246.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 280.4ms\n",
      "Speed: 7.0ms preprocess, 280.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 272.6ms\n",
      "Speed: 6.0ms preprocess, 272.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 248.9ms\n",
      "Speed: 6.0ms preprocess, 248.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 236.3ms\n",
      "Speed: 8.0ms preprocess, 236.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 236.4ms\n",
      "Speed: 6.0ms preprocess, 236.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 241.2ms\n",
      "Speed: 5.0ms preprocess, 241.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 238.0ms\n",
      "Speed: 6.0ms preprocess, 238.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 245.3ms\n",
      "Speed: 5.0ms preprocess, 245.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 251.0ms\n",
      "Speed: 5.0ms preprocess, 251.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 weeds, 271.4ms\n",
      "Speed: 5.0ms preprocess, 271.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 263.9ms\n",
      "Speed: 6.0ms preprocess, 263.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 312.8ms\n",
      "Speed: 7.0ms preprocess, 312.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 429.6ms\n",
      "Speed: 7.0ms preprocess, 429.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 245.6ms\n",
      "Speed: 8.0ms preprocess, 245.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 252.0ms\n",
      "Speed: 5.0ms preprocess, 252.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 255.3ms\n",
      "Speed: 5.0ms preprocess, 255.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 258.5ms\n",
      "Speed: 6.0ms preprocess, 258.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 264.6ms\n",
      "Speed: 6.0ms preprocess, 264.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 322.0ms\n",
      "Speed: 6.0ms preprocess, 322.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 278.1ms\n",
      "Speed: 9.0ms preprocess, 278.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 283.9ms\n",
      "Speed: 8.0ms preprocess, 283.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 318.1ms\n",
      "Speed: 6.0ms preprocess, 318.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 267.3ms\n",
      "Speed: 5.0ms preprocess, 267.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 254.7ms\n",
      "Speed: 6.0ms preprocess, 254.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 278.3ms\n",
      "Speed: 7.0ms preprocess, 278.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 273.6ms\n",
      "Speed: 12.0ms preprocess, 273.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 258.9ms\n",
      "Speed: 8.0ms preprocess, 258.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 253.0ms\n",
      "Speed: 7.0ms preprocess, 253.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 264.9ms\n",
      "Speed: 15.0ms preprocess, 264.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 235.5ms\n",
      "Speed: 6.0ms preprocess, 235.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 239.2ms\n",
      "Speed: 6.0ms preprocess, 239.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 269.7ms\n",
      "Speed: 4.0ms preprocess, 269.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 249.2ms\n",
      "Speed: 5.0ms preprocess, 249.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 256.4ms\n",
      "Speed: 6.0ms preprocess, 256.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 239.2ms\n",
      "Speed: 5.0ms preprocess, 239.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 257.3ms\n",
      "Speed: 7.0ms preprocess, 257.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 245.6ms\n",
      "Speed: 7.0ms preprocess, 245.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 248.3ms\n",
      "Speed: 5.0ms preprocess, 248.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 238.0ms\n",
      "Speed: 4.0ms preprocess, 238.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 234.5ms\n",
      "Speed: 6.0ms preprocess, 234.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 237.2ms\n",
      "Speed: 4.0ms preprocess, 237.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 240.5ms\n",
      "Speed: 5.5ms preprocess, 240.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 243.4ms\n",
      "Speed: 5.0ms preprocess, 243.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 250.3ms\n",
      "Speed: 5.0ms preprocess, 250.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 251.0ms\n",
      "Speed: 5.0ms preprocess, 251.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 237.3ms\n",
      "Speed: 4.0ms preprocess, 237.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 291.4ms\n",
      "Speed: 5.0ms preprocess, 291.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 266.5ms\n",
      "Speed: 4.0ms preprocess, 266.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 342.2ms\n",
      "Speed: 8.0ms preprocess, 342.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 390.1ms\n",
      "Speed: 9.0ms preprocess, 390.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 379.8ms\n",
      "Speed: 5.0ms preprocess, 379.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 303.4ms\n",
      "Speed: 7.0ms preprocess, 303.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 359.6ms\n",
      "Speed: 9.0ms preprocess, 359.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 360.2ms\n",
      "Speed: 6.0ms preprocess, 360.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 323.9ms\n",
      "Speed: 7.0ms preprocess, 323.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 285.9ms\n",
      "Speed: 6.0ms preprocess, 285.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 276.5ms\n",
      "Speed: 5.1ms preprocess, 276.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 275.3ms\n",
      "Speed: 8.0ms preprocess, 275.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 299.8ms\n",
      "Speed: 7.0ms preprocess, 299.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 453.7ms\n",
      "Speed: 5.0ms preprocess, 453.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 1012.1ms\n",
      "Speed: 8.0ms preprocess, 1012.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 503.2ms\n",
      "Speed: 8.0ms preprocess, 503.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 487.1ms\n",
      "Speed: 7.0ms preprocess, 487.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 428.1ms\n",
      "Speed: 9.1ms preprocess, 428.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 291.9ms\n",
      "Speed: 7.0ms preprocess, 291.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 285.1ms\n",
      "Speed: 6.0ms preprocess, 285.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 249.0ms\n",
      "Speed: 7.0ms preprocess, 249.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 247.1ms\n",
      "Speed: 5.0ms preprocess, 247.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 263.3ms\n",
      "Speed: 5.0ms preprocess, 263.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 248.7ms\n",
      "Speed: 5.0ms preprocess, 248.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 273.6ms\n",
      "Speed: 6.5ms preprocess, 273.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 255.8ms\n",
      "Speed: 5.5ms preprocess, 255.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 9 weeds, 272.8ms\n",
      "Speed: 6.0ms preprocess, 272.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 318.4ms\n",
      "Speed: 5.5ms preprocess, 318.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 429.3ms\n",
      "Speed: 13.0ms preprocess, 429.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 284.6ms\n",
      "Speed: 6.0ms preprocess, 284.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 334.5ms\n",
      "Speed: 5.0ms preprocess, 334.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 388.7ms\n",
      "Speed: 29.8ms preprocess, 388.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 323.7ms\n",
      "Speed: 8.5ms preprocess, 323.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 437.5ms\n",
      "Speed: 10.3ms preprocess, 437.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 999.3ms\n",
      "Speed: 8.0ms preprocess, 999.3ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 1019.0ms\n",
      "Speed: 14.0ms preprocess, 1019.0ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 874.1ms\n",
      "Speed: 14.0ms preprocess, 874.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 249.3ms\n",
      "Speed: 6.0ms preprocess, 249.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 316.1ms\n",
      "Speed: 7.1ms preprocess, 316.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 275.4ms\n",
      "Speed: 4.5ms preprocess, 275.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 280.0ms\n",
      "Speed: 4.0ms preprocess, 280.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 281.7ms\n",
      "Speed: 5.5ms preprocess, 281.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 274.0ms\n",
      "Speed: 4.0ms preprocess, 274.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 291.9ms\n",
      "Speed: 3.0ms preprocess, 291.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 307.0ms\n",
      "Speed: 4.0ms preprocess, 307.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 310.3ms\n",
      "Speed: 7.6ms preprocess, 310.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 371.8ms\n",
      "Speed: 7.0ms preprocess, 371.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 500.7ms\n",
      "Speed: 6.5ms preprocess, 500.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 331.9ms\n",
      "Speed: 10.1ms preprocess, 331.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 320.0ms\n",
      "Speed: 9.0ms preprocess, 320.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 278.3ms\n",
      "Speed: 5.0ms preprocess, 278.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 279.1ms\n",
      "Speed: 7.0ms preprocess, 279.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 297.3ms\n",
      "Speed: 8.0ms preprocess, 297.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 281.1ms\n",
      "Speed: 8.2ms preprocess, 281.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 296.2ms\n",
      "Speed: 5.0ms preprocess, 296.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 322.7ms\n",
      "Speed: 5.0ms preprocess, 322.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 312.8ms\n",
      "Speed: 4.5ms preprocess, 312.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 297.6ms\n",
      "Speed: 11.0ms preprocess, 297.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 245.2ms\n",
      "Speed: 5.0ms preprocess, 245.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 289.8ms\n",
      "Speed: 5.0ms preprocess, 289.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 279.4ms\n",
      "Speed: 5.0ms preprocess, 279.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 274.6ms\n",
      "Speed: 8.0ms preprocess, 274.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 313.9ms\n",
      "Speed: 5.0ms preprocess, 313.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 352.1ms\n",
      "Speed: 9.0ms preprocess, 352.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 417.6ms\n",
      "Speed: 4.0ms preprocess, 417.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 330.5ms\n",
      "Speed: 5.0ms preprocess, 330.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 280.4ms\n",
      "Speed: 4.0ms preprocess, 280.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 256.8ms\n",
      "Speed: 9.1ms preprocess, 256.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 269.2ms\n",
      "Speed: 7.0ms preprocess, 269.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 248.2ms\n",
      "Speed: 9.0ms preprocess, 248.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 258.2ms\n",
      "Speed: 6.0ms preprocess, 258.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 252.2ms\n",
      "Speed: 7.0ms preprocess, 252.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 255.3ms\n",
      "Speed: 8.0ms preprocess, 255.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 267.8ms\n",
      "Speed: 8.0ms preprocess, 267.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 279.1ms\n",
      "Speed: 5.0ms preprocess, 279.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 275.6ms\n",
      "Speed: 7.5ms preprocess, 275.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 242.7ms\n",
      "Speed: 4.5ms preprocess, 242.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 280.2ms\n",
      "Speed: 5.0ms preprocess, 280.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 269.6ms\n",
      "Speed: 52.8ms preprocess, 269.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 247.5ms\n",
      "Speed: 5.0ms preprocess, 247.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 236.0ms\n",
      "Speed: 4.0ms preprocess, 236.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 247.3ms\n",
      "Speed: 9.0ms preprocess, 247.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 299.8ms\n",
      "Speed: 8.0ms preprocess, 299.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 254.2ms\n",
      "Speed: 4.0ms preprocess, 254.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 238.3ms\n",
      "Speed: 5.0ms preprocess, 238.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 237.9ms\n",
      "Speed: 3.5ms preprocess, 237.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 weeds, 231.6ms\n",
      "Speed: 11.2ms preprocess, 231.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Processing complete. Output saved at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUTPUT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 71\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m results \u001b[38;5;241m=\u001b[39m model(frame, conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Iterate through results (usually just one per frame)\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[0;32m     51\u001b[0m     annotated_frame \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mplot() \u001b[38;5;66;03m# Draws boxes + labels\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# Write the frame to the output video\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:35\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 35\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:255\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 255\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference(im, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\ultralytics\\engine\\predictor.py:143\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    139\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    142\u001b[0m )\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\autobackend.py:510\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 510\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(im, augment\u001b[38;5;241m=\u001b[39maugment, visualize\u001b[38;5;241m=\u001b[39mvisualize, embed\u001b[38;5;241m=\u001b[39membed)\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:112\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:130\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_once(x, profile, visualize, embed)\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:151\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 151\u001b[0m x \u001b[38;5;241m=\u001b[39m m(x)  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    152\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 238\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:238\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 238\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(m(y[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\block.py:346\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    345\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Applies the YOLO FPN to input data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\ultralytics\\nn\\modules\\conv.py:54\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     53\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform transposed convolution of 2D data.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x))\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\dhamo\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to trained model\n",
    "MODEL_PATH = \"best.pt\"\n",
    "\n",
    "# Path to your input video\n",
    "VIDEO_PATH = \"..\\dataset\\weed detection simulation video - Made with Clipchamp.mp4\"  # <--- Update this path\n",
    "\n",
    "# Output folder\n",
    "OUTPUT_DIR = \"output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_DIR, \"output_video.mp4\")\n",
    "\n",
    "def main():\n",
    "    # Load model\n",
    "    model = YOLO(MODEL_PATH)\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Get video properties for the output writer\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    # 'mp4v' is a common codec for .mp4 files\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "    out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (width, height))\n",
    "\n",
    "    print(f\"Processing video... Press 'q' to stop early.\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if not success:\n",
    "            break # End of video\n",
    "\n",
    "        # Run inference on the frame\n",
    "        # stream=True is recommended for videos to manage memory\n",
    "        results = model(frame, conf=0.3, stream=True)\n",
    "\n",
    "        # Iterate through results (usually just one per frame)\n",
    "        for r in results:\n",
    "            annotated_frame = r.plot() # Draws boxes + labels\n",
    "\n",
    "            # Write the frame to the output video\n",
    "            out.write(annotated_frame)\n",
    "\n",
    "            # Display the frame in a window\n",
    "            cv2.imshow(\"Weed Detection\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release everything when done\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(f\"âœ… Processing complete. Output saved at: {OUTPUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path to trained model\n",
    "MODEL_PATH = \"best.pt\"\n",
    "VIDEO_PATH = \"..\\dataset\\weed detection simulation video.mp4\" # <--- Update this\n",
    "\n",
    "# Output setup\n",
    "OUTPUT_DIR = \"output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OUTPUT_PATH = os.path.join(OUTPUT_DIR, \"weed_count_output.mp4\")\n",
    "\n",
    "def main():\n",
    "    # Load model\n",
    "    model = YOLO(MODEL_PATH)\n",
    "\n",
    "    cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open video.\")\n",
    "        return\n",
    "\n",
    "    # Video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(OUTPUT_PATH, fourcc, fps, (width, height))\n",
    "\n",
    "    # Set to store unique object IDs (avoids double counting)\n",
    "    unique_weed_ids = set()\n",
    "\n",
    "    print(\"Processing video... Press 'q' to stop.\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Run Object Tracking (persist=True is required for tracking)\n",
    "        results = model.track(frame, conf=0.3, persist=True)\n",
    "\n",
    "        for r in results:\n",
    "            # Check if there are any detections with IDs\n",
    "            if r.boxes.id is not None:\n",
    "                # Get the IDs as integers\n",
    "                track_ids = r.boxes.id.int().cpu().tolist()\n",
    "                \n",
    "                # Add new IDs to our set\n",
    "                for track_id in track_ids:\n",
    "                    unique_weed_ids.add(track_id)\n",
    "\n",
    "            # Draw the standard tracking visualization\n",
    "            annotated_frame = r.plot()\n",
    "\n",
    "            # (Optional) Overlay the count on the video\n",
    "            cv2.putText(annotated_frame, f\"Total Weeds: {len(unique_weed_ids)}\", (20, 50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            out.write(annotated_frame)\n",
    "            cv2.imshow(\"Weed Tracking\", annotated_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    print(\"------------------------------------------------\")\n",
    "    print(f\"âœ… Processing complete.\")\n",
    "    print(f\"ğŸŒ± Total Unique Weeds Detected: {len(unique_weed_ids)}\")\n",
    "    print(f\"ğŸ“ Video saved at: {OUTPUT_PATH}\")\n",
    "    print(\"------------------------------------------------\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
